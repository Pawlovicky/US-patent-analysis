{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "import xml.etree.cElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "import zipfile\n",
    "import lxml\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patent_extraction_utils as peu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselink = 'https://bulkdata.uspto.gov/data/patent/grant/redbook/bibliographic/'\n",
    "for year in range(1991, 2019, 1):\n",
    "    link = baselink + str(year) + '/'\n",
    "    target_dir = '../data/grants_bibliography/'+str(year)+'/'\n",
    "    peu.download_all_links(link, target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_all_links(lnk, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_applications(year):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:57.0) Gecko\"\\\n",
    "               \"/20100101 Firefox/57.0\",}\n",
    "\n",
    "    lnk = 'https://bulkdata.uspto.gov/data/patent/application/redbook/fulltext/'\\\n",
    "          + str(year) + '/'\n",
    "    rr = requests.get(lnk, headers=headers)\n",
    "    html = rr.content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    urls = [x.get('href') for x in soup.find_all('a') \n",
    "            if '.zip' in x.get('href')]\n",
    "    target_dir = 'data/apps/' + str(year) + '/'\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    [urllib.request.urlretrieve(lnk + x, \n",
    "                                'data/apps/' + str(year) + '/'+x) for\n",
    "     x in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2017\n",
    "#download_applications(year)\n",
    "olddir = os.getcwd()\n",
    "newdir = '/work/data/apps/' + str(year) + '/'\n",
    "os.chdir(newdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file(fnm):\n",
    "    zip_ref = zipfile.ZipFile(fnm, 'r')\n",
    "    zip_ref.extractall('.')\n",
    "    zip_ref.close()\n",
    "    return fnm.split('/')[-1].replace('.zip', '.xml')\n",
    "\n",
    "def split_files():\n",
    "    for fnm in [x for x in os.listdir() if x.split('.')[-1]=='zip']:\n",
    "        fnm_xml = unzip_file(fnm)\n",
    "        print(fnm_xml)\n",
    "        !bash /work/split_apps.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " {fnm_xml}\n",
    "        !rm {fnm}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Meta Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_singles_from_xpath(tree, xpath):\n",
    "    fsub = tree.xpath(xpath)\n",
    "    if fsub == []:\n",
    "        return ''\n",
    "    return ''.join(fsub[0].itertext())\n",
    "\n",
    "def extract_dict_from_xpath(tree, xpath):\n",
    "    fsub = tree.xpath(xpath)\n",
    "    if fsub == []:\n",
    "        return {}\n",
    "    ref_dict = {x.tag: x.text for x in fsub[0].iterchildren()}\n",
    "    ref_dict.update({'len':len(fsub)})\n",
    "    return ref_dict\n",
    "\n",
    "def extract_all_singles_from_xpath(tree, xpaths):\n",
    "    out = {v:extract_singles_from_xpath(tree, k) for k, v in xpaths.items()}\n",
    "    return out\n",
    "    \n",
    "def extract_all_xpath_dicts(tree, xpaths):\n",
    "    keys = []\n",
    "    values = []\n",
    "    \n",
    "    for k, v in xpaths.items():\n",
    "        edict = extract_dict_from_xpath(tree, k)\n",
    "        keys.extend([v + '_' + x for x in edict.keys()])\n",
    "        values.extend(list(edict.values()))\n",
    "    \n",
    "    edict = dict(zip(keys, values))\n",
    "    return edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details_from_xml(fnm):\n",
    "    tree = etree.parse(fnm)\n",
    "    xpaths_singles = {\n",
    "        '/us-patent-application/us-bibliographic-data-application/assignees/'+\\\n",
    "        'assignee/addressbook/orgname': 'assignee',\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'invention-title': 'title',\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'us-parties/us-applicants/us-applicant/addressbook/orgname': \n",
    "        'us-applicant'\n",
    "    }\n",
    "    \n",
    "    xpaths_dicts = {\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'application-reference/document-id': 'app',\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'publication-reference/document-id': 'pub'\n",
    "    }\n",
    "    out_dict = extract_all_singles_from_xpath(tree, xpaths_singles)\n",
    "    out_dict.update(extract_all_xpath_dicts(tree, xpaths_dicts))\n",
    "    out_dict.update({'fnm':fnm})\n",
    "    return out_dict\n",
    "\n",
    "def get_details_from_folder(file_dir):\n",
    "    dict_list = [get_details_from_xml(file_dir + x) for x in \n",
    "                                     os.listdir(file_dir)]\n",
    "    df = pd.DataFrame.from_dict(dict_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details_from_all_folders(basedir, year):\n",
    "    df = [get_details_from_folder(basedir + x + '/') for x in \n",
    "           os.listdir(basedir)]\n",
    "    df = pd.concat(df)\n",
    "    df.to_csv('/work/data/apps/' + str(year) + '_all_apps.csv')\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_year(year):\n",
    "    os.chdir('/work/')\n",
    "    download_applications(year)\n",
    "    olddir = os.getcwd()\n",
    "    newdir = '/work/data/apps/' + str(year) + '/'\n",
    "    print(newdir)\n",
    "    os.chdir(newdir)\n",
    "    split_files()\n",
    "    get_details_from_all_folders(newdir, year)\n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsplit_year(year):\n",
    "    os.chdir('/work/')\n",
    "    download_applications(year)\n",
    "    olddir = os.getcwd()\n",
    "    newdir = '/work/data/apps/' + str(year) + '/'\n",
    "    print(newdir)\n",
    "    os.chdir(newdir)\n",
    "    #split_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(list(range(2006, 2019, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/data/apps/2012/\n",
      "/work/data/apps/2011/\n",
      "/work/data/apps/2010/\n",
      "/work/data/apps/2009/\n"
     ]
    }
   ],
   "source": [
    "[dsplit_year(x) for x in  list(reversed(list(range(2005, 2013, 1))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "outdfs = [make_year(x) for x in  list(reversed(list(range(2005, 2019, 1))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(list(range(2005, 2016, 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Looking at the doc-numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_singles_from_xpath(tree, xpath):\n",
    "    fsub = tree.xpath(xpath)\n",
    "    if fsub == []:\n",
    "        return ''\n",
    "    return ''.join(fsub[0].itertext())\n",
    "\n",
    "def extract_dict_from_xpath(tree, xpath):\n",
    "    fsub = tree.xpath(xpath)\n",
    "    if fsub == []:\n",
    "        return {}\n",
    "    ref_dict = {x.tag: x.text for x in fsub[0].iterchildren()}\n",
    "    ref_dict.update({'len':len(fsub)})\n",
    "    return ref_dict\n",
    "\n",
    "def extract_all_singles_from_xpath(tree, xpaths):\n",
    "    out = {v:extract_singles_from_xpath(tree, k) for k, v in xpaths.items()}\n",
    "    return out\n",
    "    \n",
    "def extract_all_xpath_dicts(tree, xpaths):\n",
    "    keys = []\n",
    "    values = []\n",
    "    \n",
    "    for k, v in xpaths.items():\n",
    "        edict = extract_dict_from_xpath(tree, k)\n",
    "        keys.extend([v + '_' + x for x in edict.keys()])\n",
    "        values.extend(list(edict.values()))\n",
    "    \n",
    "    edict = dict(zip(keys, values))\n",
    "    return edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details_from_xml(fnm):\n",
    "    tree = etree.parse(fnm)\n",
    "    xpaths_singles = {\n",
    "        '/us-patent-application/us-bibliographic-data-application/assignees/'+\\\n",
    "        'assignee/addressbook/orgname': 'assignee',\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'invention-title': 'title',\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'us-parties/us-applicants/us-applicant/addressbook/orgname': \n",
    "        'us-applicant'\n",
    "    }\n",
    "    \n",
    "    xpaths_dicts = {\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'application-reference/document-id': 'app',\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'publication-reference/document-id': 'pub'\n",
    "    }\n",
    "    out_dict = extract_all_singles_from_xpath(tree, xpaths_singles)\n",
    "    out_dict.update(extract_all_xpath_dicts(tree, xpaths_dicts))\n",
    "    out_dict.update({'fnm':fnm})\n",
    "    return out_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details_from_folder(file_dir):\n",
    "    #from IPython.core.debugger import Tracer; Tracer()()\n",
    "    dict_list = [get_details_from_xml(file_dir + x) for x in \n",
    "                                     os.listdir(file_dir)]\n",
    "    df = pd.DataFrame.from_dict(dict_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_df = get_details_from_folder('/work/data/apps/2017/ipa170202/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basedir = '/work/data/apps/2017/'\n",
    "dfs = [get_details_from_folder(basedir + x + '/') for x in os.listdir(basedir)]\n",
    "pd.concat(dfs).to_csv('/work/data/apps/2017_all_apps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_country</th>\n",
       "      <th>app_date</th>\n",
       "      <th>app_doc-number</th>\n",
       "      <th>app_len</th>\n",
       "      <th>assignee</th>\n",
       "      <th>fnm</th>\n",
       "      <th>pub_country</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>pub_doc-number</th>\n",
       "      <th>pub_kind</th>\n",
       "      <th>pub_len</th>\n",
       "      <th>title</th>\n",
       "      <th>us-applicant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>20151203</td>\n",
       "      <td>15540631</td>\n",
       "      <td>1</td>\n",
       "      <td>Bridgestone Americas Tire Operations, LLC</td>\n",
       "      <td>/work/data/apps/2017/ipa171221/F_1722.xml</td>\n",
       "      <td>US</td>\n",
       "      <td>20171221</td>\n",
       "      <td>20170361662</td>\n",
       "      <td>A1</td>\n",
       "      <td>1</td>\n",
       "      <td>RADAR WEAR SENSING FOR TIRE APPLICATIONS</td>\n",
       "      <td>Bridgestone Americas Tire Operations, LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>20151204</td>\n",
       "      <td>15532203</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/work/data/apps/2017/ipa171221/F_959.xml</td>\n",
       "      <td>US</td>\n",
       "      <td>20171221</td>\n",
       "      <td>20170360899</td>\n",
       "      <td>A1</td>\n",
       "      <td>1</td>\n",
       "      <td>TREATING SEIZURE WITH RECOMBINANT ALKALINE PHO...</td>\n",
       "      <td>Alexion Pharmaceuticals, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>20151203</td>\n",
       "      <td>15532255</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/work/data/apps/2017/ipa171221/F_1012.xml</td>\n",
       "      <td>US</td>\n",
       "      <td>20171221</td>\n",
       "      <td>20170360952</td>\n",
       "      <td>A1</td>\n",
       "      <td>1</td>\n",
       "      <td>BIOMOLECULE CONJUGATES</td>\n",
       "      <td>CELGENE CORPORATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>20151203</td>\n",
       "      <td>15533313</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/work/data/apps/2017/ipa171221/F_2534.xml</td>\n",
       "      <td>US</td>\n",
       "      <td>20171221</td>\n",
       "      <td>20170362474</td>\n",
       "      <td>A1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonding Method and Conveyor Belt</td>\n",
       "      <td>The Yokohama Rubber Co., Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>20151207</td>\n",
       "      <td>15533160</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/work/data/apps/2017/ipa171221/F_1033.xml</td>\n",
       "      <td>US</td>\n",
       "      <td>20171221</td>\n",
       "      <td>20170360973</td>\n",
       "      <td>A1</td>\n",
       "      <td>1</td>\n",
       "      <td>ELECTROCHEMICAL DEVICE FOR RELEASING IONS</td>\n",
       "      <td>NMR Technology AS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  app_country  app_date  app_doc-number  app_len  \\\n",
       "0          US  20151203        15540631        1   \n",
       "1          US  20151204        15532203        1   \n",
       "2          US  20151203        15532255        1   \n",
       "3          US  20151203        15533313        1   \n",
       "4          US  20151207        15533160        1   \n",
       "\n",
       "                                    assignee  \\\n",
       "0  Bridgestone Americas Tire Operations, LLC   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "\n",
       "                                         fnm pub_country  pub_date  \\\n",
       "0  /work/data/apps/2017/ipa171221/F_1722.xml          US  20171221   \n",
       "1   /work/data/apps/2017/ipa171221/F_959.xml          US  20171221   \n",
       "2  /work/data/apps/2017/ipa171221/F_1012.xml          US  20171221   \n",
       "3  /work/data/apps/2017/ipa171221/F_2534.xml          US  20171221   \n",
       "4  /work/data/apps/2017/ipa171221/F_1033.xml          US  20171221   \n",
       "\n",
       "   pub_doc-number pub_kind  pub_len  \\\n",
       "0     20170361662       A1        1   \n",
       "1     20170360899       A1        1   \n",
       "2     20170360952       A1        1   \n",
       "3     20170362474       A1        1   \n",
       "4     20170360973       A1        1   \n",
       "\n",
       "                                               title  \\\n",
       "0           RADAR WEAR SENSING FOR TIRE APPLICATIONS   \n",
       "1  TREATING SEIZURE WITH RECOMBINANT ALKALINE PHO...   \n",
       "2                             BIOMOLECULE CONJUGATES   \n",
       "3                   Bonding Method and Conveyor Belt   \n",
       "4          ELECTROCHEMICAL DEVICE FOR RELEASING IONS   \n",
       "\n",
       "                                us-applicant  \n",
       "0  Bridgestone Americas Tire Operations, LLC  \n",
       "1              Alexion Pharmaceuticals, Inc.  \n",
       "2                        CELGENE CORPORATION  \n",
       "3              The Yokohama Rubber Co., Ltd.  \n",
       "4                          NMR Technology AS  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_apps = pd.read_csv('/work/data/apps/2017_all_apps.csv', low_memory=False).iloc[:, 1:]\n",
    "all_apps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for y in list(reversed(list(range(2006, 2019, 1)))):\n",
    "    newdir = '/work/data/apps/' + str(y) + '/'\n",
    "    os.chdir(newdir)\n",
    "    get_details_from_all_folders(newdir, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
