{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "import xml.etree.cElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "import zipfile\n",
    "import lxml\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/work/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_applications(year):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:57.0) Gecko\"\\\n",
    "               \"/20100101 Firefox/57.0\",}\n",
    "\n",
    "    lnk = 'https://bulkdata.uspto.gov/data/patent/application/redbook/fulltext/'\\\n",
    "          + str(year) + '/'\n",
    "    rr = requests.get(lnk, headers=headers)\n",
    "    html = rr.content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    urls = [x.get('href') for x in soup.find_all('a') \n",
    "            if '.zip' in x.get('href')]\n",
    "    target_dir = 'data/apps/' + str(year) + '/'\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    [urllib.request.urlretrieve(lnk + x, \n",
    "                                'data/apps/' + str(year) + '/'+x) for\n",
    "     x in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2017\n",
    "#download_applications(year)\n",
    "olddir = os.getcwd()\n",
    "newdir = '/work/data/apps/' + str(year) + '/'\n",
    "os.chdir(newdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_file(fnm):\n",
    "    zip_ref = zipfile.ZipFile(fnm, 'r')\n",
    "    zip_ref.extractall('.')\n",
    "    zip_ref.close()\n",
    "    return fnm.split('/')[-1].replace('.zip', '.xml')\n",
    "\n",
    "def split_files():\n",
    "    for fnm in [x for x in os.listdir() if x.split('.')[-1]=='zip']:\n",
    "        fnm_xml = unzip_file(fnm)\n",
    "        print(fnm_xml)\n",
    "        !bash /work/split_apps.sh {fnm_xml}\n",
    "        !rm {fnm}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Meta Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_singles_from_xpath(tree, xpath):\n",
    "    fsub = tree.xpath(xpath)\n",
    "    if fsub == []:\n",
    "        return ''\n",
    "    return ''.join(fsub[0].itertext())\n",
    "\n",
    "def extract_dict_from_xpath(tree, xpath):\n",
    "    fsub = tree.xpath(xpath)\n",
    "    if fsub == []:\n",
    "        return {}\n",
    "    ref_dict = {x.tag: x.text for x in fsub[0].iterchildren()}\n",
    "    ref_dict.update({'len':len(fsub)})\n",
    "    return ref_dict\n",
    "\n",
    "def extract_all_singles_from_xpath(tree, xpaths):\n",
    "    out = {v:extract_singles_from_xpath(tree, k) for k, v in xpaths.items()}\n",
    "    return out\n",
    "    \n",
    "def extract_all_xpath_dicts(tree, xpaths):\n",
    "    keys = []\n",
    "    values = []\n",
    "    \n",
    "    for k, v in xpaths.items():\n",
    "        edict = extract_dict_from_xpath(tree, k)\n",
    "        keys.extend([v + '_' + x for x in edict.keys()])\n",
    "        values.extend(list(edict.values()))\n",
    "    \n",
    "    edict = dict(zip(keys, values))\n",
    "    return edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details_from_xml(fnm):\n",
    "    tree = etree.parse(fnm)\n",
    "    xpaths_singles = {\n",
    "        '/us-patent-application/us-bibliographic-data-application/assignees/'+\\\n",
    "        'assignee/addressbook/orgname': 'assignee',\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'invention-title': 'title',\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'us-parties/us-applicants/us-applicant/addressbook/orgname': \n",
    "        'us-applicant'\n",
    "    }\n",
    "    \n",
    "    xpaths_dicts = {\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'application-reference/document-id': 'app',\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'publication-reference/document-id': 'pub'\n",
    "    }\n",
    "    out_dict = extract_all_singles_from_xpath(tree, xpaths_singles)\n",
    "    out_dict.update(extract_all_xpath_dicts(tree, xpaths_dicts))\n",
    "    out_dict.update({'fnm':fnm})\n",
    "    return out_dict\n",
    "\n",
    "def get_details_from_folder(file_dir):\n",
    "    dict_list = [get_details_from_xml(file_dir + x) for x in \n",
    "                                     os.listdir(file_dir)]\n",
    "    df = pd.DataFrame.from_dict(dict_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details_from_all_folders(basedir, year):\n",
    "    df = [get_details_from_folder(basedir + x + '/') for x in \n",
    "           os.listdir(basedir)]\n",
    "    df = pd.concat(df)\n",
    "    df.to_csv('/work/data/apps/' + str(year) + '_all_apps.csv')\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_year(year):\n",
    "    os.chdir('/work/')\n",
    "    download_applications(year)\n",
    "    olddir = os.getcwd()\n",
    "    newdir = '/work/data/apps/' + str(year) + '/'\n",
    "    print(newdir)\n",
    "    os.chdir(newdir)\n",
    "    split_files()\n",
    "    get_details_from_all_folders(newdir, year)\n",
    "    return meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsplit_year(year):\n",
    "    os.chdir('/work/')\n",
    "    download_applications(year)\n",
    "    olddir = os.getcwd()\n",
    "    newdir = '/work/data/apps/' + str(year) + '/'\n",
    "    print(newdir)\n",
    "    os.chdir(newdir)\n",
    "    #split_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(list(range(2006, 2019, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for y in list(reversed(list(range(2006, 2019, 1)))):\n",
    "    newdir = '/work/data/apps/' + str(y) + '/'\n",
    "    os.chdir(newdir)\n",
    "    get_details_from_all_folders(newdir, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/data/apps/2012/\n",
      "/work/data/apps/2011/\n",
      "/work/data/apps/2010/\n",
      "/work/data/apps/2009/\n"
     ]
    }
   ],
   "source": [
    "[dsplit_year(x) for x in  list(reversed(list(range(2005, 2013, 1))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "outdfs = [make_year(x) for x in  list(reversed(list(range(2005, 2019, 1))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(list(range(2005, 2016, 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Looking at the doc-numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_singles_from_xpath(tree, xpath):\n",
    "    fsub = tree.xpath(xpath)\n",
    "    if fsub == []:\n",
    "        return ''\n",
    "    return ''.join(fsub[0].itertext())\n",
    "\n",
    "def extract_dict_from_xpath(tree, xpath):\n",
    "    fsub = tree.xpath(xpath)\n",
    "    if fsub == []:\n",
    "        return {}\n",
    "    ref_dict = {x.tag: x.text for x in fsub[0].iterchildren()}\n",
    "    ref_dict.update({'len':len(fsub)})\n",
    "    return ref_dict\n",
    "\n",
    "def extract_all_singles_from_xpath(tree, xpaths):\n",
    "    out = {v:extract_singles_from_xpath(tree, k) for k, v in xpaths.items()}\n",
    "    return out\n",
    "    \n",
    "def extract_all_xpath_dicts(tree, xpaths):\n",
    "    keys = []\n",
    "    values = []\n",
    "    \n",
    "    for k, v in xpaths.items():\n",
    "        edict = extract_dict_from_xpath(tree, k)\n",
    "        keys.extend([v + '_' + x for x in edict.keys()])\n",
    "        values.extend(list(edict.values()))\n",
    "    \n",
    "    edict = dict(zip(keys, values))\n",
    "    return edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details_from_xml(fnm):\n",
    "    tree = etree.parse(fnm)\n",
    "    xpaths_singles = {\n",
    "        '/us-patent-application/us-bibliographic-data-application/assignees/'+\\\n",
    "        'assignee/addressbook/orgname': 'assignee',\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'invention-title': 'title',\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'us-parties/us-applicants/us-applicant/addressbook/orgname': \n",
    "        'us-applicant'\n",
    "    }\n",
    "    \n",
    "    xpaths_dicts = {\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'application-reference/document-id': 'app',\n",
    "        '/us-patent-application/us-bibliographic-data-application/'+\\\n",
    "        'publication-reference/document-id': 'pub'\n",
    "    }\n",
    "    out_dict = extract_all_singles_from_xpath(tree, xpaths_singles)\n",
    "    out_dict.update(extract_all_xpath_dicts(tree, xpaths_dicts))\n",
    "    out_dict.update({'fnm':fnm})\n",
    "    return out_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details_from_folder(file_dir):\n",
    "    #from IPython.core.debugger import Tracer; Tracer()()\n",
    "    dict_list = [get_details_from_xml(file_dir + x) for x in \n",
    "                                     os.listdir(file_dir)]\n",
    "    df = pd.DataFrame.from_dict(dict_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "all_df = get_details_from_folder('/work/data/apps/2017/ipa170202/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basedir = '/work/data/apps/2017/'\n",
    "dfs = [get_details_from_folder(basedir + x + '/') for x in os.listdir(basedir)]\n",
    "pd.concat(dfs).to_csv('/work/data/apps/2017_all_apps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_apps = pd.read_csv('/work/data/apps/2017_all_apps.csv', low_memory=False).iloc[:, 1:]\n",
    "all_apps.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
